{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Machine Learning Models - Vanilla Price Prediction\n",
    "\n",
    "Ce notebook impl√©mente plusieurs mod√®les de pr√©diction:\n",
    "1. **Baseline**: Moyenne mobile, ARIMA\n",
    "2. **Machine Learning**: Random Forest, XGBoost\n",
    "3. **Deep Learning**: Prophet (Facebook)\n",
    "4. **√âvaluation et comparaison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML imports\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# Time series\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import pmdarima as pm\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = Path('../data/processed')\n",
    "MODEL_PATH = Path('../models')\n",
    "OUTPUT_PATH = Path('../outputs/figures')\n",
    "\n",
    "# Config\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donn√©es\n",
    "df = pd.read_csv(DATA_PATH / 'vanilla_prices_clean.csv', parse_dates=['date'])\n",
    "df = df.set_index('date')\n",
    "\n",
    "print(f\"üìä Dataset: {len(df)} observations\")\n",
    "print(f\"üìÖ P√©riode: {df.index.min().date()} ‚Üí {df.index.max().date()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pr√©paration des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features et target\n",
    "target = 'price_usd_kg'\n",
    "\n",
    "features = [\n",
    "    'year', 'month', 'quarter',\n",
    "    'harvest_season', 'cyclone_season',\n",
    "    'price_lag1', 'price_lag3', 'price_lag6', 'price_lag12',\n",
    "    'price_ma3', 'price_ma6', 'price_ma12',\n",
    "    'price_pct_change', 'price_volatility'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "print(f\"Features: {len(features)}\")\n",
    "print(f\"Observations: {len(X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split temporel (80% train, 20% test)\n",
    "# IMPORTANT: Pour les s√©ries temporelles, on ne fait PAS de shuffle!\n",
    "\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_idx = df.index[:train_size]\n",
    "test_idx = df.index[train_size:]\n",
    "\n",
    "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
    "y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
    "\n",
    "print(f\"üìä Train: {len(X_train)} observations ({df.index[0].date()} ‚Üí {df.index[train_size-1].date()})\")\n",
    "print(f\"üìä Test: {len(X_test)} observations ({df.index[train_size].date()} ‚Üí {df.index[-1].date()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úÖ Features scaled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fonctions d'√©valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"Calcule et affiche les m√©triques d'√©valuation\"\"\"\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    print(f\"\\nüìä {model_name} - R√©sultats:\")\n",
    "    print(f\"   RMSE: ${rmse:.2f}\")\n",
    "    print(f\"   MAE:  ${mae:.2f}\")\n",
    "    print(f\"   MAPE: {mape:.2f}%\")\n",
    "    print(f\"   R¬≤:   {r2:.4f}\")\n",
    "    \n",
    "    return {'model': model_name, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2}\n",
    "\n",
    "def plot_predictions(y_true, y_pred, dates, model_name):\n",
    "    \"\"\"Visualise les pr√©dictions vs r√©alit√©\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Time series plot\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(dates, y_true, 'b-', label='R√©el', linewidth=2)\n",
    "    ax1.plot(dates, y_pred, 'r--', label='Pr√©dit', linewidth=2)\n",
    "    ax1.fill_between(dates, y_true, y_pred, alpha=0.3, color='gray')\n",
    "    ax1.set_title(f'{model_name} - Pr√©dictions vs R√©alit√©', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Prix (USD/kg)')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax2 = axes[1]\n",
    "    ax2.scatter(y_true, y_pred, alpha=0.6, edgecolors='black')\n",
    "    ax2.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', linewidth=2)\n",
    "    ax2.set_title(f'{model_name} - Scatter Plot', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Prix R√©el (USD/kg)')\n",
    "    ax2.set_ylabel('Prix Pr√©dit (USD/kg)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_PATH / f'{model_name.lower().replace(\" \", \"_\")}_predictions.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "# Stocker les r√©sultats\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mod√®le Baseline - Moyenne Mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: pr√©dire avec la moyenne mobile des 3 derniers mois\n",
    "y_pred_baseline = X_test['price_ma3'].values\n",
    "\n",
    "result = evaluate_model(y_test.values, y_pred_baseline, 'Baseline (MA3)')\n",
    "results.append(result)\n",
    "\n",
    "plot_predictions(y_test.values, y_pred_baseline, test_idx, 'Baseline MA3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SARIMA (Seasonal ARIMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-ARIMA pour trouver les meilleurs param√®tres\n",
    "print(\"üîç Recherche des param√®tres optimaux SARIMA...\")\n",
    "\n",
    "auto_arima = pm.auto_arima(\n",
    "    y_train,\n",
    "    seasonal=True,\n",
    "    m=12,  # Saisonnalit√© mensuelle\n",
    "    stepwise=True,\n",
    "    suppress_warnings=True,\n",
    "    error_action='ignore',\n",
    "    max_p=3, max_q=3,\n",
    "    max_P=2, max_Q=2,\n",
    "    trace=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Meilleur mod√®le: {auto_arima.summary()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions SARIMA\n",
    "y_pred_sarima = auto_arima.predict(n_periods=len(y_test))\n",
    "\n",
    "result = evaluate_model(y_test.values, y_pred_sarima, 'SARIMA')\n",
    "results.append(result)\n",
    "\n",
    "plot_predictions(y_test.values, y_pred_sarima, test_idx, 'SARIMA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "result = evaluate_model(y_test.values, y_pred_rf, 'Random Forest')\n",
    "results.append(result)\n",
    "\n",
    "plot_predictions(y_test.values, y_pred_rf, test_idx, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'], color='steelblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Random Forest - Importance des Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PATH / 'rf_feature_importance.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    eval_set=[(X_test_scaled, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "result = evaluate_model(y_test.values, y_pred_xgb, 'XGBoost')\n",
    "results.append(result)\n",
    "\n",
    "plot_predictions(y_test.values, y_pred_xgb, test_idx, 'XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prophet (Facebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet n√©cessite un format sp√©cifique\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    \n",
    "    # Pr√©parer les donn√©es pour Prophet\n",
    "    df_prophet_train = pd.DataFrame({\n",
    "        'ds': train_idx,\n",
    "        'y': y_train.values\n",
    "    })\n",
    "    \n",
    "    df_prophet_test = pd.DataFrame({\n",
    "        'ds': test_idx\n",
    "    })\n",
    "    \n",
    "    # Cr√©er et entra√Æner le mod√®le\n",
    "    prophet_model = Prophet(\n",
    "        yearly_seasonality=True,\n",
    "        weekly_seasonality=False,\n",
    "        daily_seasonality=False,\n",
    "        changepoint_prior_scale=0.05\n",
    "    )\n",
    "    prophet_model.fit(df_prophet_train)\n",
    "    \n",
    "    # Pr√©dictions\n",
    "    forecast = prophet_model.predict(df_prophet_test)\n",
    "    y_pred_prophet = forecast['yhat'].values\n",
    "    \n",
    "    result = evaluate_model(y_test.values, y_pred_prophet, 'Prophet')\n",
    "    results.append(result)\n",
    "    \n",
    "    plot_predictions(y_test.values, y_pred_prophet, test_idx, 'Prophet')\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Prophet non install√©. Ex√©cuter: pip install prophet\")\n",
    "    print(\"   Skipping Prophet model...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparaison des mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau comparatif\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('RMSE')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä COMPARAISON DES MOD√àLES\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"\\nüèÜ Meilleur mod√®le:\", results_df.iloc[0]['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['RMSE', 'MAE', 'MAPE', 'R2']\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "\n",
    "for i, (metric, ax) in enumerate(zip(metrics, axes.flat)):\n",
    "    values = results_df[metric].values\n",
    "    models = results_df['model'].values\n",
    "    \n",
    "    bars = ax.barh(models, values, color=colors[i], edgecolor='black')\n",
    "    ax.set_xlabel(metric)\n",
    "    ax.set_title(f'Comparaison - {metric}', fontweight='bold')\n",
    "    \n",
    "    # Annoter les valeurs\n",
    "    for bar, val in zip(bars, values):\n",
    "        if metric == 'MAPE':\n",
    "            ax.text(val + 0.5, bar.get_y() + bar.get_height()/2, f'{val:.1f}%', va='center')\n",
    "        elif metric == 'R2':\n",
    "            ax.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.3f}', va='center')\n",
    "        else:\n",
    "            ax.text(val + 1, bar.get_y() + bar.get_height()/2, f'${val:.1f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PATH / 'model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Pr√©dictions futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliser le meilleur mod√®le pour pr√©dire 12 mois dans le futur\n",
    "best_model_name = results_df.iloc[0]['model']\n",
    "print(f\"\\nüîÆ Pr√©dictions avec {best_model_name} pour les 12 prochains mois:\")\n",
    "\n",
    "# G√©n√©rer les pr√©dictions avec SARIMA (plus adapt√© pour forecast futur)\n",
    "future_predictions = auto_arima.predict(n_periods=12)\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.DateOffset(months=1), periods=12, freq='MS')\n",
    "\n",
    "future_df = pd.DataFrame({\n",
    "    'Date': future_dates,\n",
    "    'Prix Pr√©dit (USD/kg)': future_predictions\n",
    "})\n",
    "\n",
    "print(future_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des pr√©dictions futures\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Donn√©es historiques\n",
    "plt.plot(df.index, df['price_usd_kg'], 'b-', label='Historique', linewidth=2)\n",
    "\n",
    "# Pr√©dictions futures\n",
    "plt.plot(future_dates, future_predictions, 'r--', label='Pr√©dictions 2025', linewidth=2, marker='o')\n",
    "\n",
    "# Zone de confiance (approximative)\n",
    "std = df['price_usd_kg'].std() * 0.3\n",
    "plt.fill_between(future_dates, \n",
    "                 future_predictions - std, \n",
    "                 future_predictions + std, \n",
    "                 alpha=0.3, color='red', label='Intervalle de confiance')\n",
    "\n",
    "plt.axvline(x=df.index[-1], color='gray', linestyle='--', alpha=0.5)\n",
    "plt.title('Pr√©diction du Prix de la Vanille - 12 Prochains Mois', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Prix (USD/kg)')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PATH / 'future_predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sauvegarde des mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Sauvegarder les mod√®les\n",
    "joblib.dump(rf_model, MODEL_PATH / 'random_forest_model.joblib')\n",
    "joblib.dump(xgb_model, MODEL_PATH / 'xgboost_model.joblib')\n",
    "joblib.dump(scaler, MODEL_PATH / 'scaler.joblib')\n",
    "joblib.dump(auto_arima, MODEL_PATH / 'sarima_model.joblib')\n",
    "\n",
    "# Sauvegarder les r√©sultats\n",
    "results_df.to_csv(MODEL_PATH / 'model_results.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Mod√®les sauvegard√©s dans models/\")\n",
    "print(\"   - random_forest_model.joblib\")\n",
    "print(\"   - xgboost_model.joblib\")\n",
    "print(\"   - sarima_model.joblib\")\n",
    "print(\"   - scaler.joblib\")\n",
    "print(\"   - model_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã R√©sum√©\n",
    "\n",
    "### Mod√®les test√©s:\n",
    "1. Baseline (Moyenne Mobile 3 mois)\n",
    "2. SARIMA (Auto-tuned)\n",
    "3. Random Forest\n",
    "4. XGBoost\n",
    "5. Prophet (si install√©)\n",
    "\n",
    "### Prochaines am√©liorations possibles:\n",
    "- Hyperparameter tuning avec GridSearchCV\n",
    "- Ensemble methods (stacking)\n",
    "- Ajouter features externes (taux de change, m√©t√©o)\n",
    "- LSTM pour deep learning\n",
    "\n",
    "### Utilisation:\n",
    "```python\n",
    "import joblib\n",
    "model = joblib.load('models/xgboost_model.joblib')\n",
    "scaler = joblib.load('models/scaler.joblib')\n",
    "prediction = model.predict(scaler.transform(new_data))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
